# Pipeline to build a nucleotide library

Builds libraries of dinucleotide and trinucleotide RNA fragments, at 0.5A and 1.0A precision.

In addition, this repo contains:

- Fragment clustering tools
- An algorithm to calculate the closest fit (nearest neighbour) of a fragment, excluding fragments from the same PDB;
- An algorithm to quickly estimate the completeness of a set of fragments. Completeness is defined as the percentage of the fragments that have a closest fit within a certain RMSD threshold.
- A tool and interactive notebook that uses the above algorithms to calculate the closest fit and completeness for a given Rfam/Pfam family, i.e. considering only fragments from outside the family as candidates for the closest fit. **This notebook can be run online in the browser, no need to download or install any files**

## Obtaining the library

The library consists of sublibraries built at the dinucleotide and trinucleotide level, for each sequence motif and for each precision level (0.5A and 1A). Sequence motifs contain every combination of A and C (4 resp. 8 motifs for dinucleotide and trinucleotide). To extend to A/C/G/U, `lib-mutate.py` must be run after the library has been obtained.

There are three ways to obtain the fragment library.

First, you can run the current pipeline and build the library yourself, as explained in the next section.

Alternatively, instead of building the library yourself, you can download it from the [nucleotide library Git repo](https://github.com/sjdv1982/nucleotide-library).

Finally, the current repo also contains a `download-library.sh` script, which clones the nucleotide library repo and copies its contents into the `output/` and `library/` folders. This allows you to run the closest fit and completeness notebooks from the current repo.

## Library building instructions

### Step 1. Download nucleotide fragments and fragment PDB templates

The main input of the pipeline is a coordinate array of nonredundant nucleotide fragments, previously generated by the nucleotide fragment pipeline.

The secondary input is PDB template files, in order to know the residue and atom names of the coordinates.

Both of these are defined as Git submodules. Run the following command to download them:

`git submodule update --init --recursive --progress`

### Step 2. Run the clustering

Clustering is performed using a pairwise RMSD (after Kabsch superposition) cutoff that corresponds to the desired precision. Clustering is performed for each sublibrary with an extra clustering at 2.0A (used for the closest fit computation later on).

For each clustering, the result is obtained by a removing iteratively the largest cluster from the fragment pool. The 50 largest clusters are determined probabilistically; for the remaining fragment pool, the full pairwise RMSD matrix is computed.

After the clustering is done, the origin (PDB code provenance) of each cluster is analyzed.

Scripts to run:

- clust.sh (or equivalent script with parallel cluster jobs)
- clust-origin.sh

### Step 3. Build the library

Script to run:

- build-library.sh (or equivalent script with parallel cluster jobs)

## Closest fit computation

This repo contains an algorithm that calculates the closest fit (nearest-neighbour)
of each fragment, excluding fragments from the same PDB.

The algorithm is based on multi-resolution analysis, i.e. it takes multiple clusterings and selects/eliminates clusters and fragments based on RMSD triangle inequalities. This is approximately 3-5 times faster than brute force.

Scripts to run:

- closest-fit.sh (or equivalent script with parallel cluster jobs)
- The `closest-fit-analysis` notebook to verify the calculation against a brute force approach.

## Completeness analysis

This repo contains an algorithm to quickly estimate the completeness of a set of fragments. It is based on direct analysis of the clustering.

Completeness is defined as the percentage of the fragments for which there exists at least one other fragment(excluding fragments from the same PDB) within a certain RMSD threshold. The brute force approach to compute the closest fitting fragment explicitly. However, even with the multi-resolution approach above, this takes several hours to compute.

In contrast, the direct clustering analysis only requires a clustering at the precision that is equal to the RMSD threshold. After that, the completeness analysis runs within seconds.

Scripts to run:

- Inside the `verification` folder: `classify-fragments.sh`.

- Inside the `verification` folder: one of the `check-all` scripts. `check-all.sh` is the fastest, but this requires that the closest fit analysis in `output/` has been completed first. If this has not been done, you can download it from GitHub using the `download-library.sh` script.
- The notebook in the `verification/` subfolder, to compare the calculation again brute force.

## Context-specific analysis

This repo contains a tool and interactive notebook that uses the above algorithms to calculate the closest fit and completeness in a *context-specific* manner. Here, *context* means a binary label that a fragment has or has not: the closest fit and completeness are calculated for all fragments within the context, but only fragments without the context are considered as candidates for the closest fit.
An experienced user can supply their own context labeling, but two have been implemented here:

- Is the fragment associated with a certain protein domain family (Pfam)? If the fragment is part of at least one complex where a member of that Pfam interacts with RNA, then the context is positive, else it is negative.
  
- Is the fragment associated with a certain RNA family (Rfam)?

An interactive notebook is provided where the user chooses a library (dinuc or trinuc), a database (Rfam or Pfam), and a family ID. The notebook then quickly computes (an estimate of) the context-specific completeness and then computes the closest fit RMSD, which is then plotted as a histogram. It is possible to select a sample (for each motif) from all fragments with the context. In that case,the calculation will finish within a few minutes, otherwise it takes up to an hour or two (for the largest families).

Script to run:

- Inside the `context-specific` subfolder: the `completess` notebook.

This notebook can be executed online, without any installation on the user's computer:

- In Google Colab, using [this link](https://colab.research.google.com/github/sjdv1982/nucleotide-build-library/blob/main/context-specific/completeness.ipynb)

- In Binder, using [this link](https://mybinder.org/v2/gh/sjdv1982/nucleotide-build-library/HEAD?urlpath=%2Fdoc%2Ftree%2Fcontext-specific%2Fcompleteness.ipynb)
